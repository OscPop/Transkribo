{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matching timestamps\n",
    "The teams transcriptions come with accurate timestamps for individual speakers since they are using separate microphones. Unfortunately, whisper does not have automatic knowledge of who's saying what. To make up for this, the transcribed speech from whisper is matched with the teams transcription timestamp.\n",
    "<br><br>\n",
    "This is achieved by taking a sentence from the whisper transcription and looking at its timestamp (start/end times). A specific sentence is then assigned the speaker tag of the time section with the most overlapping time from the teams transcription. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "\n",
    "folder_path = os.path.join(\"\")\n",
    "if not os.path.exists(folder_path):\n",
    "    print(f\"Folder does not exist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Teams transcription in tsv-format\n",
    "df_teams = pd.read_csv(os.path.join(folder_path, \"teams.tsv\"), sep=\"\\t\")\n",
    "\n",
    "print(f\"Shape of df: {df_teams.shape}\")\n",
    "df_teams.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Whisper transcription in tsv-format\n",
    "df_whisper = pd.read_csv(os.path.join(folder_path, \"whisper_transcription_large-v2.tsv\"), sep=\"\\t\")\n",
    "\n",
    "print(f\"Shape of df: {df_whisper.shape}\")\n",
    "df_whisper.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to find the closest timestamp in df2 to a given timestamp in df1\n",
    "def find_overlap(start1, end1, start2, end2):\n",
    "    overlap = min(end1, end2) - max(start1, start2)\n",
    "\n",
    "    if overlap < 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return overlap\n",
    "    \n",
    "\n",
    "# Function to format the timestamp\n",
    "def format_timestamp(seconds: float, always_include_hours: bool = False, decimal_marker: str = '.'):\n",
    "    assert seconds >= 0, \"non-negative timestamp expected\"\n",
    "    milliseconds = round(seconds * 1000.0)\n",
    "\n",
    "    hours = milliseconds // 3_600_000\n",
    "    milliseconds -= hours * 3_600_000\n",
    "\n",
    "    minutes = milliseconds // 60_000\n",
    "    milliseconds -= minutes * 60_000\n",
    "\n",
    "    seconds = milliseconds // 1_000\n",
    "    milliseconds -= seconds * 1_000\n",
    "\n",
    "    hours_marker = f\"{hours:02d}:\" if always_include_hours or hours > 0 else \"\"\n",
    "    return f\"{hours_marker}{minutes:02d}:{seconds:02d}{decimal_marker}{milliseconds:03d}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle offset/misalignment in speech-to-text\n",
    "\n",
    "\n",
    "offset = 200    # milliseconds\n",
    "\n",
    "# Calculate offset based on timestamps in team transcription and audio\n",
    "hour_teams, minute_teams, second_teams = 0, 2, 46\n",
    "milli_teams = int(hour_teams * 60*60*1000 + minute_teams * 60*1000 + second_teams * 1000)\n",
    "\n",
    "hour_audio, minute_audio, second_audio = 0, 2, 50\n",
    "milli_audio = int(hour_audio * 60*60*1000 + minute_audio * 60*1000 + second_audio * 1000)\n",
    "\n",
    "#offset = milli_audio - milli_teams\n",
    "print(offset)\n",
    "\n",
    "# Make an empty column for speaker\n",
    "df_whisper[\"speaker\"] = np.zeros(df_whisper.shape[0])\n",
    "\n",
    "# Loop over all rows in whisper transcription\n",
    "for i in range(df_whisper.shape[0]):\n",
    "    start1, end1 = df_whisper[[\"start\", \"end\"]].iloc[i]\n",
    "\n",
    "    # Find the row in team transcription with the most overlap with the current row in whisper transcription\n",
    "    amount_of_overlap = df_teams.apply(lambda row: find_overlap(start1=start1, end1=end1, \n",
    "                                        start2=row[\"start\"]+offset, \n",
    "                                        end2=row[\"end\"]+offset), \n",
    "                                        axis=1)\n",
    "    \n",
    "    # Get index of row with most overlap\n",
    "    index_max = np.argmax(amount_of_overlap)\n",
    "\n",
    "    # Extract speaker from team transcription and add to whisper transcription\n",
    "    speaker = df_teams.loc[index_max, \"speaker\"]\n",
    "    df_whisper.loc[i, \"speaker\"] = speaker\n",
    "\n",
    "# Change column order and save to file\n",
    "df_whisper = df_whisper[[\"start\", \"end\", \"speaker\", \"text\"]]\n",
    "df_whisper.to_csv(os.path.join(folder_path, \"text_whisper_offset_adjusted.tsv\"), index=False, sep=\"\\t\")\n",
    "\n",
    "df_whisper.head(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
